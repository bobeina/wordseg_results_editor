分词结果人工校对程序
===================================
该项目框架取自Tornado Blog example，还有很多细节没来得及修，例如docker配置文件等，
如果对权限及安全等要求不高，大致上是可以用了。
运行RNN分词算法所需的配置文件是基于微软的MSR训练的，在生成的时候有一些问题可能需要
重新进行生成，但是影响不大（反正都分得不甚准确），等我重训练后再放上来。也可以改用
其它的分词程序。
MongoDB库名：rawtext
语料文档结构如下：
> db.text.findOne()
{
	"_id" : ObjectId("591d74ef6244626420e753a0"),
	"batch" : "201705180001",
	"raw" : "原始文本串",
	"summary" : "摘要在这里",
	"cut" : [
		"使用",
		"分词",
		"程序",
		"初步",
		"分词",
		"的",
		"结果"
	],
	"status" : 2,
	"info" : {
		"field" : [
			"财经",
			"新闻"
		],
		"source" : "来源",
		"author" : "作者",
		"url" : "http://...",
		"savetime" : ISODate("2012-03-21T00:00:00Z"), # 文本获取的时间
		"time" : 文本发布时间
	},
	"create_time" : ISODate("2017-05-18T10:15:35.044Z"),
	"creator" : {
		"name" : "redsky",
		"email" : "minvacai@sina.com"
	}
	"proofreaded" : [
		"人工",
		"校对",
		"后",
		"的",
		"结果"
	],
}

Yang D.Y.
2017/5/22 16:02

